#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
åˆ›å»ºç¤ºä¾‹æ•°æ®é›†ç”¨äºæµ‹è¯•æœºå™¨å­¦ä¹ åŠŸèƒ½
"""

import pandas as pd
import numpy as np
import os
from sklearn.datasets import make_classification, make_regression
from datetime import datetime, timedelta

def create_sample_datasets():
    """åˆ›å»ºå„ç§ç±»å‹çš„ç¤ºä¾‹æ•°æ®é›†"""
    
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    data_dir = os.path.join(os.path.dirname(__file__), 'data', 'samples')
    os.makedirs(data_dir, exist_ok=True)
    
    print("æ­£åœ¨åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")
    
    # 1. åˆ†ç±»æ•°æ®é›† - å­¦ç”Ÿæˆç»©é¢„æµ‹
    print("åˆ›å»ºåˆ†ç±»æ•°æ®é›†: å­¦ç”Ÿæˆç»©é¢„æµ‹...")
    np.random.seed(42)
    n_samples = 1000
    
    # ç”Ÿæˆç‰¹å¾
    study_hours = np.random.normal(6, 2, n_samples)
    attendance = np.random.uniform(0.7, 1.0, n_samples)
    previous_score = np.random.normal(75, 15, n_samples)
    homework_completion = np.random.uniform(0.6, 1.0, n_samples)
    sleep_hours = np.random.normal(7, 1.5, n_samples)
    
    # è®¡ç®—æœ€ç»ˆæˆç»©ï¼ˆæœ‰ä¸€å®šéšæœºæ€§ï¼‰
    final_score = (
        study_hours * 5 + 
        attendance * 20 + 
        previous_score * 0.3 + 
        homework_completion * 15 + 
        sleep_hours * 2 + 
        np.random.normal(0, 5, n_samples)
    )
    
    # è½¬æ¢ä¸ºç­‰çº§
    grade_category = pd.cut(final_score, 
                           bins=[0, 60, 70, 80, 90, 100], 
                           labels=['ä¸åŠæ ¼', 'åŠæ ¼', 'è‰¯å¥½', 'ä¼˜ç§€', 'æ°å‡º'])
    
    student_data = pd.DataFrame({
        'å­¦ä¹ æ—¶é—´_å°æ—¶': np.clip(study_hours, 0, 12),
        'å‡ºå‹¤ç‡': np.clip(attendance, 0, 1),
        'ä¹‹å‰æˆç»©': np.clip(previous_score, 0, 100),
        'ä½œä¸šå®Œæˆç‡': np.clip(homework_completion, 0, 1),
        'ç¡çœ æ—¶é—´_å°æ—¶': np.clip(sleep_hours, 4, 12),
        'æœ€ç»ˆæˆç»©': np.clip(final_score, 0, 100),
        'æˆç»©ç­‰çº§': grade_category
    })
    
    student_data.to_csv(os.path.join(data_dir, 'å­¦ç”Ÿæˆç»©é¢„æµ‹.csv'), index=False, encoding='utf-8-sig')
    
    # 2. å›å½’æ•°æ®é›† - æˆ¿ä»·é¢„æµ‹
    print("åˆ›å»ºå›å½’æ•°æ®é›†: æˆ¿ä»·é¢„æµ‹...")
    np.random.seed(42)
    n_houses = 800
    
    area = np.random.normal(120, 40, n_houses)
    bedrooms = np.random.randint(1, 6, n_houses)
    bathrooms = np.random.randint(1, 4, n_houses)
    age = np.random.randint(0, 50, n_houses)
    distance_to_center = np.random.uniform(1, 30, n_houses)
    
    # æˆ¿ä»·è®¡ç®—ï¼ˆæœ‰å™ªéŸ³ï¼‰
    price = (
        area * 8000 + 
        bedrooms * 50000 + 
        bathrooms * 30000 - 
        age * 2000 - 
        distance_to_center * 5000 + 
        np.random.normal(0, 100000, n_houses)
    )
    
    house_data = pd.DataFrame({
        'é¢ç§¯_å¹³ç±³': np.clip(area, 30, 300),
        'å§å®¤æ•°é‡': bedrooms,
        'æµ´å®¤æ•°é‡': bathrooms,
        'æˆ¿é¾„_å¹´': age,
        'è·å¸‚ä¸­å¿ƒè·ç¦»_å…¬é‡Œ': distance_to_center,
        'æˆ¿ä»·_ä¸‡å…ƒ': np.clip(price, 100000, 2000000) / 10000
    })
    
    house_data.to_csv(os.path.join(data_dir, 'æˆ¿ä»·é¢„æµ‹.csv'), index=False, encoding='utf-8-sig')
    
    # 3. å®¢æˆ·åˆ†ç¾¤æ•°æ®é›†
    print("åˆ›å»ºèšç±»æ•°æ®é›†: å®¢æˆ·åˆ†ç¾¤...")
    np.random.seed(42)
    n_customers = 500
    
    # åˆ›å»º3ä¸ªå®¢æˆ·ç¾¤ä½“
    # ç¾¤ä½“1: é«˜ä»·å€¼å®¢æˆ·
    age1 = np.random.normal(45, 8, n_customers//3)
    income1 = np.random.normal(150000, 30000, n_customers//3)
    spending1 = np.random.normal(80000, 15000, n_customers//3)
    
    # ç¾¤ä½“2: ä¸­ç­‰ä»·å€¼å®¢æˆ·
    age2 = np.random.normal(35, 10, n_customers//3)
    income2 = np.random.normal(80000, 20000, n_customers//3)
    spending2 = np.random.normal(40000, 10000, n_customers//3)
    
    # ç¾¤ä½“3: ä½ä»·å€¼å®¢æˆ·
    age3 = np.random.normal(28, 12, n_customers - 2*(n_customers//3))
    income3 = np.random.normal(45000, 15000, n_customers - 2*(n_customers//3))
    spending3 = np.random.normal(20000, 8000, n_customers - 2*(n_customers//3))
    
    customer_data = pd.DataFrame({
        'å¹´é¾„': np.concatenate([age1, age2, age3]),
        'å¹´æ”¶å…¥_ä¸‡å…ƒ': np.concatenate([income1, income2, income3]) / 10000,
        'å¹´æ¶ˆè´¹_ä¸‡å…ƒ': np.concatenate([spending1, spending2, spending3]) / 10000,
        'ä¼šå‘˜å¹´é™': np.random.randint(1, 15, n_customers),
        'è´­ä¹°é¢‘æ¬¡_æ¬¡æ¯æœˆ': np.random.randint(1, 20, n_customers)
    })
    
    customer_data = customer_data.sample(frac=1).reset_index(drop=True)  # æ‰“ä¹±é¡ºåº
    customer_data.to_csv(os.path.join(data_dir, 'å®¢æˆ·åˆ†ç¾¤.csv'), index=False, encoding='utf-8-sig')
    
    # 4. æ–‡æœ¬åˆ†ç±»æ•°æ®é›† - äº§å“è¯„è®ºæƒ…æ„Ÿåˆ†æ
    print("åˆ›å»ºæ–‡æœ¬åˆ†ç±»æ•°æ®é›†: äº§å“è¯„è®ºæƒ…æ„Ÿåˆ†æ...")
    
    positive_comments = [
        "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œè´¨é‡å¾ˆæ£’ï¼",
        "ç‰©æµå¾ˆå¿«ï¼ŒåŒ…è£…å¾ˆå¥½ï¼Œéå¸¸æ»¡æ„",
        "æ€§ä»·æ¯”å¾ˆé«˜ï¼Œæ¨èè´­ä¹°",
        "åŠŸèƒ½å¼ºå¤§ï¼Œæ“ä½œç®€å•ï¼Œå€¼å¾—æ¨è",
        "è´¨é‡è¶…å‡ºé¢„æœŸï¼ŒæœåŠ¡æ€åº¦å¾ˆå¥½",
        "å¤–è§‚è®¾è®¡å¾ˆæ¼‚äº®ï¼Œç”¨èµ·æ¥å¾ˆé¡ºæ‰‹",
        "ä»·æ ¼å®æƒ ï¼Œè´¨é‡ä¸é”™",
        "å¿«é€’å¾ˆå¿«ï¼Œå•†å“å’Œæè¿°ä¸€è‡´",
        "å®¢æœæ€åº¦å¾ˆå¥½ï¼Œè§£ç­”å¾ˆåŠæ—¶",
        "è¿™æ˜¯æˆ‘ä¹°è¿‡æœ€å¥½çš„äº§å“äº†"
    ] * 30
    
    negative_comments = [
        "è´¨é‡å¤ªå·®äº†ï¼Œç”¨äº†å‡ å¤©å°±åäº†",
        "åŒ…è£…ç ´æŸï¼Œå•†å“æœ‰ç‘•ç–µ",
        "ä¸æè¿°ä¸ç¬¦ï¼Œå¾ˆå¤±æœ›",
        "ç‰©æµå¤ªæ…¢äº†ï¼Œç­‰äº†å¾ˆä¹…",
        "å®¢æœæ€åº¦å¾ˆå·®ï¼Œä¸æ¨è",
        "ä»·æ ¼å¤ªè´µï¼Œä¸å€¼å¾—",
        "åŠŸèƒ½æœ‰é—®é¢˜ï¼Œæ“ä½œå¤æ‚",
        "å¤–è§‚å¾ˆä¸‘ï¼Œåšå·¥ç²—ç³™",
        "é€€è´§å¾ˆéº»çƒ¦ï¼ŒæœåŠ¡ä¸å¥½",
        "å®Œå…¨ä¸ç¬¦åˆé¢„æœŸï¼Œæµªè´¹é’±"
    ] * 30
    
    neutral_comments = [
        "è¿˜å¯ä»¥å§ï¼Œä¸€èˆ¬èˆ¬",
        "ä»·æ ¼åˆç†ï¼Œè´¨é‡è¿˜è¡Œ",
        "æ™®æ™®é€šé€šï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„",
        "åŸºæœ¬åŠŸèƒ½éƒ½æœ‰ï¼Œå‡‘åˆç”¨",
        "ç‰©æµä¸€èˆ¬ï¼ŒåŒ…è£…è¿˜è¡Œ",
        "ç¬¦åˆé¢„æœŸï¼Œæ²¡æœ‰æƒŠå–œ",
        "ä¸­è§„ä¸­çŸ©çš„äº§å“",
        "è¿˜ç®—æ»¡æ„ï¼Œæœ‰æ”¹è¿›ç©ºé—´",
        "æ€§ä»·æ¯”ä¸€èˆ¬ï¼Œä¸ç®—ç‰¹åˆ«å¥½",
        "å¯ä»¥æ¥å—ï¼Œä½†ä¸ä¼šå†ä¹°"
    ] * 20
    
    comments_data = pd.DataFrame({
        'è¯„è®ºå†…å®¹': positive_comments + negative_comments + neutral_comments,
        'æƒ…æ„Ÿæ ‡ç­¾': ['æ­£é¢'] * 300 + ['è´Ÿé¢'] * 300 + ['ä¸­æ€§'] * 200,
        'è¯„åˆ†': [5] * 150 + [4] * 150 + [1] * 150 + [2] * 150 + [3] * 200
    })
    
    comments_data = comments_data.sample(frac=1).reset_index(drop=True)
    comments_data.to_csv(os.path.join(data_dir, 'äº§å“è¯„è®ºæƒ…æ„Ÿåˆ†æ.csv'), index=False, encoding='utf-8-sig')
    
    # 5. æ—¶é—´åºåˆ—æ•°æ®é›† - é”€å”®é¢„æµ‹
    print("åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†: é”€å”®é¢„æµ‹...")
    
    start_date = datetime(2020, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(365*3)]
    
    # ç”Ÿæˆæœ‰è¶‹åŠ¿å’Œå­£èŠ‚æ€§çš„é”€å”®æ•°æ®
    trend = np.linspace(1000, 1500, len(dates))
    seasonal = 200 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)
    weekly = 100 * np.sin(2 * np.pi * np.arange(len(dates)) / 7)
    noise = np.random.normal(0, 50, len(dates))
    
    sales = trend + seasonal + weekly + noise
    
    sales_data = pd.DataFrame({
        'æ—¥æœŸ': dates,
        'é”€å”®é¢': np.clip(sales, 0, None),
        'å‘¨å‡ ': [d.weekday() + 1 for d in dates],
        'æœˆä»½': [d.month for d in dates],
        'å­£åº¦': [(d.month - 1) // 3 + 1 for d in dates],
        'æ˜¯å¦èŠ‚å‡æ—¥': np.random.choice([0, 1], len(dates), p=[0.9, 0.1])
    })
    
    sales_data.to_csv(os.path.join(data_dir, 'é”€å”®é¢„æµ‹.csv'), index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… ç¤ºä¾‹æ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print(f"æ•°æ®å­˜å‚¨ä½ç½®: {data_dir}")
    print("\nåˆ›å»ºçš„æ•°æ®é›†:")
    print("1. å­¦ç”Ÿæˆç»©é¢„æµ‹.csv - åˆ†ç±»é—®é¢˜")
    print("2. æˆ¿ä»·é¢„æµ‹.csv - å›å½’é—®é¢˜") 
    print("3. å®¢æˆ·åˆ†ç¾¤.csv - èšç±»é—®é¢˜")
    print("4. äº§å“è¯„è®ºæƒ…æ„Ÿåˆ†æ.csv - æ–‡æœ¬åˆ†ç±»")
    print("5. é”€å”®é¢„æµ‹.csv - æ—¶é—´åºåˆ—é¢„æµ‹")
    
    return data_dir

def create_readme():
    """åˆ›å»ºæ•°æ®é›†è¯´æ˜æ–‡æ¡£"""
    readme_content = """
# ç¤ºä¾‹æ•°æ®é›†è¯´æ˜

æœ¬ç›®å½•åŒ…å«äº†ç”¨äºæµ‹è¯•æœºå™¨å­¦ä¹ åŠŸèƒ½çš„ç¤ºä¾‹æ•°æ®é›†ã€‚

## æ•°æ®é›†åˆ—è¡¨

### 1. å­¦ç”Ÿæˆç»©é¢„æµ‹.csv (åˆ†ç±»é—®é¢˜)
- **ç›®æ ‡**: æ ¹æ®å­¦ä¹ ä¹ æƒ¯é¢„æµ‹å­¦ç”Ÿæˆç»©ç­‰çº§
- **ç‰¹å¾**: å­¦ä¹ æ—¶é—´ã€å‡ºå‹¤ç‡ã€ä¹‹å‰æˆç»©ã€ä½œä¸šå®Œæˆç‡ã€ç¡çœ æ—¶é—´
- **ç›®æ ‡å˜é‡**: æˆç»©ç­‰çº§ï¼ˆä¸åŠæ ¼ã€åŠæ ¼ã€è‰¯å¥½ã€ä¼˜ç§€ã€æ°å‡ºï¼‰
- **æ ·æœ¬æ•°**: 1000æ¡

### 2. æˆ¿ä»·é¢„æµ‹.csv (å›å½’é—®é¢˜)
- **ç›®æ ‡**: æ ¹æ®æˆ¿å±‹ç‰¹å¾é¢„æµ‹æˆ¿ä»·
- **ç‰¹å¾**: é¢ç§¯ã€å§å®¤æ•°é‡ã€æµ´å®¤æ•°é‡ã€æˆ¿é¾„ã€è·å¸‚ä¸­å¿ƒè·ç¦»
- **ç›®æ ‡å˜é‡**: æˆ¿ä»·ï¼ˆä¸‡å…ƒï¼‰
- **æ ·æœ¬æ•°**: 800æ¡

### 3. å®¢æˆ·åˆ†ç¾¤.csv (èšç±»é—®é¢˜)
- **ç›®æ ‡**: åŸºäºå®¢æˆ·è¡Œä¸ºè¿›è¡Œå®¢æˆ·åˆ†ç¾¤
- **ç‰¹å¾**: å¹´é¾„ã€å¹´æ”¶å…¥ã€å¹´æ¶ˆè´¹ã€ä¼šå‘˜å¹´é™ã€è´­ä¹°é¢‘æ¬¡
- **æ ·æœ¬æ•°**: 500æ¡

### 4. äº§å“è¯„è®ºæƒ…æ„Ÿåˆ†æ.csv (æ–‡æœ¬åˆ†ç±»)
- **ç›®æ ‡**: åˆ†æäº§å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘
- **ç‰¹å¾**: è¯„è®ºå†…å®¹ã€è¯„åˆ†
- **ç›®æ ‡å˜é‡**: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ï¼‰
- **æ ·æœ¬æ•°**: 800æ¡

### 5. é”€å”®é¢„æµ‹.csv (æ—¶é—´åºåˆ—)
- **ç›®æ ‡**: é¢„æµ‹æœªæ¥é”€å”®é¢
- **ç‰¹å¾**: æ—¥æœŸã€å‘¨å‡ ã€æœˆä»½ã€å­£åº¦ã€æ˜¯å¦èŠ‚å‡æ—¥
- **ç›®æ ‡å˜é‡**: é”€å”®é¢
- **æ ·æœ¬æ•°**: 1095æ¡ï¼ˆ3å¹´æ•°æ®ï¼‰

## ä½¿ç”¨å»ºè®®

1. **åˆå­¦è€…**: å»ºè®®ä»å­¦ç”Ÿæˆç»©é¢„æµ‹æˆ–æˆ¿ä»·é¢„æµ‹å¼€å§‹
2. **è¿›é˜¶ç”¨æˆ·**: å¯ä»¥å°è¯•å®¢æˆ·åˆ†ç¾¤æˆ–æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
3. **é«˜çº§ç”¨æˆ·**: å¯ä»¥æ¢ç´¢æ—¶é—´åºåˆ—é¢„æµ‹

## å®éªŒå»ºè®®

### åˆ†ç±»å®éªŒ
```
ä½¿ç”¨å­¦ç”Ÿæˆç»©é¢„æµ‹æ•°æ®ï¼Œå°è¯•ä¸åŒçš„åˆ†ç±»ç®—æ³•ï¼š
- é€»è¾‘å›å½’
- å†³ç­–æ ‘
- éšæœºæ£®æ—
- æ”¯æŒå‘é‡æœº
```

### å›å½’å®éªŒ
```
ä½¿ç”¨æˆ¿ä»·é¢„æµ‹æ•°æ®ï¼Œæ¯”è¾ƒå›å½’ç®—æ³•æ€§èƒ½ï¼š
- çº¿æ€§å›å½’
- å†³ç­–æ ‘å›å½’
- éšæœºæ£®æ—å›å½’
```

### é›†æˆå­¦ä¹ å®éªŒ
```
ä½¿ç”¨æŠ•ç¥¨æˆ–å †å æ–¹æ³•ç»„åˆå¤šä¸ªæ¨¡å‹ï¼Œè§‚å¯Ÿæ€§èƒ½æå‡ã€‚
```

### èšç±»å®éªŒ
```
ä½¿ç”¨å®¢æˆ·åˆ†ç¾¤æ•°æ®è¿›è¡ŒK-meansèšç±»ï¼Œæ‰¾å‡ºæœ€ä½³èšç±»æ•°é‡ã€‚
```

---
æ•°æ®ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    data_dir = os.path.join(os.path.dirname(__file__), 'data', 'samples')
    readme_path = os.path.join(data_dir, 'README.md')
    
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"ğŸ“– è¯´æ˜æ–‡æ¡£å·²åˆ›å»º: {readme_path}")

if __name__ == "__main__":
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
    data_dir = create_sample_datasets()
    
    # åˆ›å»ºè¯´æ˜æ–‡æ¡£
    create_readme()
    
    print(f"\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ•°æ®å·²å‡†å¤‡å®Œæˆï¼")
    print(f"æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨è¿™äº›æ•°æ®é›†æ¥æµ‹è¯•æœºå™¨å­¦ä¹ åŠŸèƒ½ã€‚")
    print(f"\nğŸ’¡ å¿«é€Ÿå¼€å§‹:")
    print(f"1. å¯åŠ¨åº”ç”¨: python app.py")
    print(f"2. ä¸Šä¼ æ•°æ®: é€‰æ‹© {data_dir} ä¸­çš„ä»»æ„ CSV æ–‡ä»¶")
    print(f"3. é€‰æ‹©ç›®æ ‡åˆ—è¿›è¡Œå®éªŒ")
    print(f"4. å¼€å§‹å¯¹è¯å¼æœºå™¨å­¦ä¹ å®éªŒï¼") 